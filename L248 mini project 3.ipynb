{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhuonijie/models/research/delf/delf/python/examples'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhuonijie/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Users/zhuonijie/models/research\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from delf import feature_io\n",
    "import glob\n",
    "import re\n",
    "\n",
    "cmd_args = None\n",
    "\n",
    "_DISTANCE_THRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. DELF features\n",
    "\n",
    "After extracting DELF features and visualizing DELF examples in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "# list_images contains the image paths for original and augmentation images\n",
    "with open(\"delf/delf/python/examples/list_images.txt\") as mytxt:\n",
    "    for line in mytxt:\n",
    "        images.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = glob.glob(\"delf/delf/python/examples/data/MantaRay_features/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delf/delf/python/examples/data/MantaRay_features/AUG_Gamble Sep 15th 2007_EH.JPG_0_3776.delf\n",
      "delf/delf/python/examples/data/MantaRay_features/AUG_Arnulv_EH.jpg_0_2709.delf\n"
     ]
    }
   ],
   "source": [
    "features_1 = features[0]\n",
    "features_2 = features[176]\n",
    "print(features_1)\n",
    "print(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhuonijie/models/research/delf/delf/python/feature_io.py:172: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "INFO:tensorflow:Loaded image 1's 246 features\n",
      "INFO:tensorflow:Loaded image 2's 25 features\n"
     ]
    }
   ],
   "source": [
    "# Read features.\n",
    "locations_1, _, descriptors_1, _, _ = feature_io.ReadFromFile(features_1)\n",
    "num_features_1 = locations_1.shape[0]\n",
    "tf.logging.info(\"Loaded image 1's %d features\" % num_features_1)\n",
    "\n",
    "locations_2, _, descriptors_2, _, _ = feature_io.ReadFromFile(features_2)\n",
    "num_features_2 = locations_2.shape[0]\n",
    "tf.logging.info(\"Loaded image 2's %d features\" % num_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(features)):\n",
    "    a = features[i].split('/')[-1:][0][:-5]\n",
    "    a = a.replace('.', '_')\n",
    "    a = re.split('_',a)\n",
    "    ind = a.index('EH')-1\n",
    "    labels.append(a[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest-neighbor matches using a KD tree.\n",
    "d1_tree = cKDTree(descriptors_1)\n",
    "_, indices = d1_tree.query(descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature locations for putative matches.\n",
    "locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "  ])\n",
    "locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. DELF feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-211d72c1ee87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mresidual_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       max_trials=1000)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minliers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.7/site-packages/skimage/measure/fit.py\u001b[0m in \u001b[0;36mransac\u001b[0;34m(data, model_class, min_samples, residual_threshold, is_data_valid, is_model_valid, max_trials, stop_sample_num, stop_residuals_sum, stop_probability, random_state)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0msample_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# backwards compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.7/site-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, src, dst)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             \u001b[0msrc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_center_and_normalize_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0mdst_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_center_and_normalize_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.7/site-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36m_center_and_normalize_points\u001b[0;34m(points)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mrms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n\u001b[0;32m---> 78\u001b[0;31m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_scores = []\n",
    "for i in range(719):\n",
    "    print(i)\n",
    "    features_1 = features[i]\n",
    "    locations_1, _, descriptors_1, _, _ = feature_io.ReadFromFile(features_1)\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    similarities = []\n",
    "    for j in range(i+1,720):\n",
    "        features_2 = features[j]\n",
    "        locations_2, _, descriptors_2, _, _ = feature_io.ReadFromFile(features_2)\n",
    "        num_features_2 = locations_2.shape[0]\n",
    "        \n",
    "        d1_tree = cKDTree(descriptors_1)\n",
    "        _, indices = d1_tree.query(descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "        locations_2_to_use = np.array([\n",
    "        locations_2[i,]\n",
    "        for i in range(num_features_2)\n",
    "          if indices[i] != num_features_1\n",
    "      ])\n",
    "        locations_1_to_use = np.array([\n",
    "          locations_1[indices[i],]\n",
    "        for i in range(num_features_2)\n",
    "          if indices[i] != num_features_1\n",
    "      ])\n",
    "        \n",
    "        if len(locations_1_to_use)==0 | len(locations_2_to_use)==0:\n",
    "            similarity = 0\n",
    "            similarities.append(similarity)\n",
    "            continue\n",
    "        \n",
    "        _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "        \n",
    "        if inliers is None:\n",
    "            similarity = 0\n",
    "            similarities.append(similarity)\n",
    "            continue\n",
    "        \n",
    "        # Define how similar they are\n",
    "        number_keypoints = 0\n",
    "        if num_features_1 <= num_features_2:\n",
    "            number_keypoints = num_features_1\n",
    "        else:\n",
    "            number_keypoints = num_features_2\n",
    "\n",
    "        similarity = sum(inliers)/number_keypoints\n",
    "        similarities.append(similarity)\n",
    "    new_scores.append(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_score_list = []\n",
    "for i in range(len(new_scores)):\n",
    "    new_score_tmp = new_scores[i]\n",
    "    new_score_tmp.insert(0,1)\n",
    "    for j in reversed(range(i)):\n",
    "        new_score_tmp.insert(0,new_scores[j][i-j])\n",
    "    new_score_list.append(new_score_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_1 = 0\n",
    "total_5 = 0\n",
    "total_10 = 0\n",
    "total_25 = 0\n",
    "total_50 = 0\n",
    "total_75 = 0\n",
    "total_100 = 0\n",
    "true_1 = 0\n",
    "true_5 = 0\n",
    "true_10 = 0\n",
    "true_25 = 0\n",
    "true_50 = 0\n",
    "true_75 = 0\n",
    "true_100 = 0\n",
    "\n",
    "for i in range(len(new_score_list)):\n",
    "        true_label = labels[i]\n",
    "        top_1_idx = np.argsort(new_score_list[i])[-1:]\n",
    "        top_5_idx = np.argsort(new_score_list[i])[-5:]\n",
    "        top_10_idx = np.argsort(new_score_list[i])[-10:]\n",
    "        top_25_idx = np.argsort(new_score_list[i])[-25:]\n",
    "        top_50_idx = np.argsort(new_score_list[i])[-50:]\n",
    "        top_75_idx = np.argsort(new_score_list[i])[-75:]\n",
    "        top_100_idx = np.argsort(new_score_list[i])[-100:]\n",
    "        total_1 += 1\n",
    "        total_5 += 1\n",
    "        total_10 += 1\n",
    "        total_25 += 1\n",
    "        total_50 += 1\n",
    "        total_75 += 1\n",
    "        total_100 += 1\n",
    "        for index in top_1_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    #print(i)\n",
    "                    true_1 += 1\n",
    "                    break\n",
    "        for index in top_5_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_5 += 1\n",
    "                    break\n",
    "        for index in top_10_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_10 += 1\n",
    "                    break\n",
    "        for index in top_25_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_25 += 1\n",
    "                    break\n",
    "        for index in top_50_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_50 += 1\n",
    "                    break\n",
    "        for index in top_75_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_75 += 1\n",
    "                    break\n",
    "        for index in top_100_idx:\n",
    "            #if index < len(aug_image_labels):\n",
    "                if labels[index] == true_label:\n",
    "                    true_100 += 1\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5422535211267606\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(true_1/total_1)\n",
    "print(true_5/total_5)\n",
    "print(true_10/total_10)\n",
    "print(true_25/total_25)\n",
    "print(true_50/total_50)\n",
    "print(true_75/total_75)\n",
    "print(true_100/total_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('delf_testset.txt', 'w') as f:\n",
    "    for item in features[:142]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
