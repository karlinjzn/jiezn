{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game of Thrones\n",
    "\n",
    "* Get the lists of character names\n",
    "* Use API's to download all the character pages\n",
    "* Create a network by using those pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "%matplotlib inline\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import urllib2\n",
    "import networkx as nx\n",
    "import community\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use API's to get lists of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get namelist, idlist and url list of the characters\n",
    "base=\"http://gameofthrones.wikia.com/api/v1/Articles/List?category=Characters&\"\n",
    "#Insert how many characters we want. This is just all of them.\n",
    "limit=\"limit=1057\"\n",
    "listquery=\"%s%s\" %(base,limit)\n",
    "textloadlist= json.loads(urllib2.urlopen(listquery).read())\n",
    "namelist=[]\n",
    "idlist=[]\n",
    "urllist=[]\n",
    "for i in range(len(textloadlist['items'])):\n",
    "    namelist.append(textloadlist['items'][i]['title'])\n",
    "    idlist.append(textloadlist['items'][i]['id'])\n",
    "    urllist.append(textloadlist['items'][i]['url'][6:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the lists as textfiles for easy use in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = io.open(\"char_names.txt\", 'w+',encoding=\"utf-8\") \n",
    "for item in namelist:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = io.open(\"url_names.txt\", 'w+',encoding=\"utf-8\") \n",
    "for item in urllist:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = io.open(\"id_list.txt\", 'w+',encoding=\"utf-8\") \n",
    "for item in idlist:\n",
    "    f.write(\"%s\\n\" % unicode(item))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Aemma Arryn', u'Aemon', u'Aemond Targaryen', u'Aggar', u'Aggo', u'Akho', u'Allo', u'Amaya', u'Anara', u'Andros']\n",
      "[u'Aemma_Arryn', u'Aemon', u'Aemond_Targaryen', u'Aggar', u'Aggo', u'Akho', u'Allo', u'Amaya', u'Anara', u'Andros']\n",
      "[49600, 2206, 30718, 10245, 6660, 39242, 21870, 36172, 29843, 30956]\n"
     ]
    }
   ],
   "source": [
    "print namelist[:10]\n",
    "print urllist[:10]\n",
    "print idlist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1057\n"
     ]
    }
   ],
   "source": [
    "print len(namelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the wiki page for every Game of Thrones chacter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "filedir=glob.glob('char_pages/*')\n",
    "filelist=[]\n",
    "for name in filedir:\n",
    "    filelist.append(name[11:-4].lower())\n",
    "# Get the wiki page for each character\n",
    "for i in range(len(namelist)):\n",
    "    if namelist[i].replace(\"/\", \"_\").lower() in filelist:\n",
    "        continue\n",
    "    #Use the id to access the different pages\n",
    "    query=\"http://gameofthrones.wikia.com/api/v1/Articles/AsJson?id=%s\" %idlist[i]\n",
    "    query=query.encode('utf-8')\n",
    "    response= urllib2.urlopen(query)\n",
    "    source= response.read()\n",
    "    textload=json.loads(source)\n",
    "    \n",
    "    #Write the content of the article\n",
    "    filename=\"%s.txt\" % namelist[i]\n",
    "    #Do this since / can't be used in a file name\n",
    "    filename=filename.replace(\"/\", \"_\")\n",
    "    f = io.open(filename, 'w+',encoding=\"utf-8\") \n",
    "    f.write(unicode(textload['content']))\n",
    "    f.close()\n",
    "    destname=\"char_pages/%s\" % filename\n",
    "    os.rename(filename, destname) \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a graph/network of all the characters. Do this based on who link to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Create both a directed graph and an undirected graph\n",
    "G=nx.DiGraph()\n",
    "H=nx.Graph()\n",
    "G.add_nodes_from(namelist)\n",
    "H.add_nodes_from(namelist)\n",
    "for i in range(len(namelist)):\n",
    "    name=namelist[i].replace(\"/\", \"_\")\n",
    "    url=urllist[i]\n",
    "    for p in range(len(namelist)):\n",
    "        if p==i:\n",
    "            continue\n",
    "        filename=\"char_pages/%s.txt\" % namelist[p].replace(\"/\", \"_\")\n",
    "        f = io.open(filename, 'r' ,encoding='utf-8')\n",
    "        readfile=f.read()\n",
    "        regexname=r\"\\/\" + re.escape(url) + r\"\\b\"\n",
    "        match=re.search(regexname, readfile)   \n",
    "        if match:\n",
    "            G.add_edge(namelist[p], namelist[i])\n",
    "            H.add_edge(namelist[p], namelist[i])\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the graphs as gpickle files for easy use in the future\n",
    "\n",
    "#nx.write_gpickle(G, \"Digraph_GOT.gpickle\")\n",
    "#nx.write_gpickle(H, \"Udigraph_GOT.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of edges in the graph is 9165\n",
      "The number of nodes in the graph is 1057\n",
      "The number of edges in the graph is 6759\n",
      "The number of nodes in the graph is 1057\n"
     ]
    }
   ],
   "source": [
    "#Print some simple stats to show that the graph were successfully created\n",
    "print \"The number of edges in the graph is %d\" % G.number_of_edges()\n",
    "print \"The number of nodes in the graph is %d\" % G.number_of_nodes()\n",
    "print \"The number of edges in the graph is %d\" % H.number_of_edges()\n",
    "print \"The number of nodes in the graph is %d\" % H.number_of_nodes()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
